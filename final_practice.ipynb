{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d93af7-7ac3-4590-ae02-d946399c9002",
   "metadata": {},
   "source": [
    "# Final Practice\n",
    "\n",
    "__Author: Tom Schang__\n",
    "\n",
    "Here are some problems to help prepare for the final. If you get stuck, try discussing with your classmates! It's a great method of learning. I will not be releasing solutions (except for one video-solution) because I truly don't believe solutions are helpful. You all have the tools and smarts to solve these problems; seeing the solution is a shortcut and inhibits learning.\n",
    "\n",
    "Disclaimers:\n",
    "1. The difficulty rankings may not be super accurate. If one of the easy questions turns out to be medium or hard, it is probably because I ranked it poorly, not because you don't understand something.\n",
    "2. The questions in this workbook lean a little more math-y than program-y. This is slightly different from Per's previous finals, which seem to lean a little more program-y. Nonetheless, I think this is useful practice. It will really force you to think about what you are coding before you code it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd890a8-6011-46a8-b734-94b9742d375e",
   "metadata": {},
   "source": [
    "## Recursion and data types (Easy) \n",
    "\\[Credit to HackerRank\\] Suppose someone is hanging a string of $N$ programmable lightbulbs. They are curious how many patterns they could create. At least one bulb must be on for a pattern to be considered valid. How many valid patterns are there module $10^10$? Solve this problem two ways.\n",
    "\n",
    "1. Write a recursive function that solves this problem for arbitrarily large $N$.\n",
    "2. Find a closed-form formula. Implement the formula as a function that works for arbitrarily large $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb157d-b95a-4b38-a29f-3d2333d19fa4",
   "metadata": {},
   "source": [
    "## Optimization (Easy)\n",
    "Sometimes we need to optimize a function with constraints. For example, one way to find the largest eigenvalue of a symmetric matrix $A$ is to compute \n",
    "$$\\begin{cases} \\text{maximize } x^T A x \\\\ \\text{subject to }\\Vert x \\Vert = 1\\end{cases}.$$\n",
    "One way to do this is to find all critical points of $f(x) = x^T Ax$ subject to $g(x) = \\Vert x\\Vert ^2 - 1 = 0$, which can be done using Lagrange multipliers. Specifically, critical points are solutions of the system of equations \n",
    "$$\\begin{cases} \\nabla f(x) = \\lambda \\nabla g(x)\\\\ g(x) = 0\\end{cases}$$\n",
    "where $\\lambda$ is an additional free variable (together with all the entries of $x$).\n",
    "Another way to do this is to optimize using the penalty method, i.e. to compute \n",
    "$$\\max_x f(x) - g(x)^2.$$\n",
    "\n",
    "Suppose $A = \\begin{bmatrix} 1 & 2 & 0 \\\\ 2 & 5 & -1 \\\\ 0 & -1 & -2\\end{bmatrix}$.\n",
    "1. Solve the Lagrange multiplier equations using Mathematica.\n",
    "2. Use Julia's `optimize(f, [0,0,2], GradientDescent(); autodiff=:forward)` from the `Optim` package to maximize the function from the penalty method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5bdb0-ec71-4eab-8826-d9e6afb11bcd",
   "metadata": {},
   "source": [
    "## Runtimes (Medium)\n",
    "<!-- Some formula like $\\sum kx_k$ that has different runtimes depending on how you do it. Write it out, get them to assess the runtime, then get them to re-write in a faster runtime, then do it in a 1-liner. -->\n",
    "Suppose we are given a vector $x$ of length $n$ and that we are asked to calculate \n",
    "$$\\sum_{j=1}^n \\left(\\prod_{k=1}^j x_k\\right).$$\n",
    "Classmate 1 wrote a function that does exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e21540-b7e1-4cc1-9d00-ec8cebf8198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function sum_products(x)\n",
    "    s = 0\n",
    "    for j in 1:length(x)\n",
    "        p = 1\n",
    "        for k in 1:j\n",
    "            p *= x[k]\n",
    "        end\n",
    "        s += p\n",
    "    end\n",
    "    return s\n",
    "end           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81ac79-3e84-43e0-97a1-c9ab14ce0997",
   "metadata": {},
   "source": [
    "1. What is the runtime of this function? Justify your answer.\n",
    "2. Re-write the function as a 1-liner. _\\[Hint: use the functions `sum` and `prod`\\]_\n",
    "3. Write a new function `sum_products_efficient` that has a faster runtime than classmate 1's solution. State the runtime of your more efficient implementation and justify.\n",
    "4. Re-write the function from part (3) as a 1-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da98bf5-8c72-4231-9cbb-93e5bd95802b",
   "metadata": {},
   "source": [
    "## Markov Chains (Hard)\n",
    "\n",
    "There is a common mathematical construction called the Markov chain, which can be thought of as a special type of graph. For example, the following Markov chain could be used to describe whether we are asleep or awake.\n",
    "\n",
    "![Markov Chain](markov_chain.png)\n",
    "\n",
    "Let's use some math. Suppose $V$ is the set of vertices, and suppose $E$ is the set of edges, with each edge being a triple $(v, w, \\pi)$ which represents an edge from $v$ to $w$ that has value $\\pi$. Edges may go from a vertex back to itself. A graph is defined as a pair $G=(V,E)$. A Markov chain is a graph that additionally satisfies $\\pi\\in[0,1]$ for each edge, and also that the sum of the $\\pi$ values over all edges leaving a vertex must be equal to 1 (so that it defines a probability distribution). The stationary distribution of a Markov chain is a function $P:V\\to [0,1]$ satisfying \n",
    "$$P(v) = \\sum_{e=(w,v',\\pi)\\in E} \\begin{cases} \\pi \\cdot P(w) & v' = v \\\\ 0 &\\text{otherwise}\\end{cases}.$$\n",
    "In our example, the stationary distribution is $P(s) = 1/3$ and $P(a)=2/3$. We can verify this: $P(s) = 1/3 = \\frac{1}{3}P(s) + \\frac{1}{3}P(a)$. Verify that the value for $P(a)$ is also correct.\n",
    "\n",
    "Write a function `stationary_dist(G)` that takes in a graph (assumed to represent a Markov chain/satisfy the requiremenets) and computes the stationary distribution of the Markov chain.\n",
    "\n",
    "_\\[Hint: can you write a system of linear equations to solve this problem?\\]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7146527-8d02-40fc-aaf7-0929de21cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Graph\n",
    "    vertices::Vector{Int64}\n",
    "    edges::Vector{Tuple{Int64,Int64,Float64}}\n",
    "end\n",
    "\n",
    "function stationary_dist(G::Graph)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca633cf-2b10-4e4d-9f97-f6563a6439ad",
   "metadata": {},
   "source": [
    "## Bayesian Optimization (Project-like)\n",
    "[Bayesian optimization](https://en.wikipedia.org/wiki/Bayesian_optimization#:~:text=Bayesian%20optimization%20is%20a%20sequential,expensive%2Dto%2Devaluate%20functions.) is a common strategy to optimize expensive-to-evaluate functions. For example, one may want to find the ratio of 5 compounds that has maximal tensile strength. In this case, each function evaluation (what is the tensile strength of the material made with this ratio?) is very expensive to evaluate: it requires creating the material with the new ratio, and putting it through a variety of physical experiments to determine the tensile strength. \n",
    "\n",
    "In this problem, we will implement Bayesian optimization following [Peter Frazier's tutorial](https://arxiv.org/pdf/1807.02811). This entire workbook follows materials due to him.\n",
    "\n",
    "The gist of Bayesian optimization is that given some data, we can define a probability distribution for what the true function is. In other words, given some data $D=\\{(x_1, y_1=f(x_1)),\\ldots,(x_n,y_n=f(x_n))\\}$, we should be able to compute the mean/expected value and a 95% confidence interval of $f(x)$ for any input $x$. Thus, we will need to define a function that takes in existing data and a new input $x$ and spits out the mean and variance of $f(x)$.\n",
    "\n",
    "In Julia, we will represent $D$ as a list of pairs, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a4e10-3c37-47c7-b295-f7d2b0a85b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [(3,sin(3)), (4,sin(4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a6496-8131-4c62-9f6b-2747b902df1d",
   "metadata": {},
   "source": [
    "### Prior mean\n",
    "Implement the following function. This is what we would guess the mean to be if we had no data.\n",
    "$$\\mu_0(x) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdca46-33f4-4584-87f4-e4c1b6f674d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function zero_mean(x)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd70a086-3313-473e-9f2c-2fdc68009f3e",
   "metadata": {},
   "source": [
    "### Gaussian kernel\n",
    "Implement the kernel/covariance function \n",
    "$$\\Sigma_0(x, x') = \\alpha \\exp\\left(-L\\Vert x - x'\\Vert^2\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5aab1c-98ba-4358-8f26-f591095528ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gaussian_kernel(x1, x2; α=0.2, L=50.0)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a68ae-6087-487e-ae6e-2229533abc78",
   "metadata": {},
   "source": [
    "### Predicted mean\n",
    "The predicted mean is given by \n",
    "$$\\mu(x; D) = \\mu_0(x) + \\begin{bmatrix} \\Sigma_0(x, x_1) & \\ldots & \\Sigma_0(x, x_n)\\end{bmatrix}\\begin{bmatrix} \\Sigma_0(x_1,x_1) & \\Sigma_0(x_1, x_2) &\\ldots &\\Sigma_0(x_1, x_n) \\\\ \\Sigma_0(x_2,x_1) & \\Sigma_0(x_2, x_2) &\\ldots &\\Sigma_0(x_2, x_n) \\\\\n",
    "\\vdots & \\vdots &\\ddots &\\vdots \\\\\n",
    "\\Sigma_0(x_n,x_1) & \\Sigma_0(x_n, x_2) &\\ldots &\\Sigma_0(x_n, x_n)\\end{bmatrix}\\left(\\begin{bmatrix} f(x_1)\\\\\\vdots\\\\ f(x_n)\\end{bmatrix}-\\begin{bmatrix} \\mu_0(x_1)\\\\\\vdots\\\\ \\mu_0(x_n)\\end{bmatrix}\\right).$$\n",
    "Implement a function that takes in data and a new input $x$ and computes the predicted mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd5721-876e-46ec-854a-cb9f466e6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "function μ(x, D; μ₀=zero_mean, Σ₀=gaussian_kernel)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfcca2-4343-44dc-9adf-6587304513bd",
   "metadata": {},
   "source": [
    "### Predicted variance\n",
    "The predicted variance is given by\n",
    "$$\\sigma^2(x; D) = \\Sigma_0(x,x) - \\begin{bmatrix} \\Sigma_0(x, x_1) & \\ldots & \\Sigma_0(x, x_n)\\end{bmatrix}\\begin{bmatrix} \\Sigma_0(x_1,x_1) & \\Sigma_0(x_1, x_2) &\\ldots &\\Sigma_0(x_1, x_n) \\\\ \\Sigma_0(x_2,x_1) & \\Sigma_0(x_2, x_2) &\\ldots &\\Sigma_0(x_2, x_n) \\\\\n",
    "\\vdots & \\vdots &\\ddots &\\vdots \\\\\n",
    "\\Sigma_0(x_n,x_1) & \\Sigma_0(x_n, x_2) &\\ldots &\\Sigma_0(x_n, x_n)\\end{bmatrix} ^ {-1} \\begin{bmatrix} \\Sigma_0(x, x_1)\\\\\\vdots\\\\ \\Sigma_0(x, x_n)\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e13959-c1c7-400a-b8e1-5501e90cce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function σ²(x, D; Σ₀=gaussian_kernel)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b0a6d-60f7-488a-90f9-54d9f7c4d43a",
   "metadata": {},
   "source": [
    "### Expected improvement\n",
    "The expected improvement is how we decide where to evaluate our function next to maximize our chance of finding the largest function value in the fewest number of steps. Suppose we have data $D$ as before. We let $y^\\ast = f(x^\\ast)$ be the best value (i.e. largest, if we are trying to maximize $f$) so far. Suppose also that $\\mu_x = \\mu(x;D)$, $\\sigma^2_x = \\sigma^2(x; D)$. We define the expected improvement as follows:\n",
    "$$ \\mathrm{EI}(x; D) = \\max(\\mu_x- y^\\ast, 0) + \\sigma_x\\varphi\\left(\\frac{\\mu_x- y^\\ast}{\\sigma_x}\\right) - | \\mu_x- y^\\ast|\\Phi\\left(\\frac{\\mu_x- y^\\ast}{\\sigma_x}\\right)$$\n",
    "where $\\varphi$ is the probability density function (pdf) for the standard normal distribution and $\\Phi$ is the cumulative distribution function (cdf) for the standard normal distribution. \n",
    "\n",
    "_\\[Hint: you should find a package to evaluate the pdf and cdf of the standard normal distribution.\\]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20455c4-a48c-49ea-840f-7119f816a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function EI(μₓ, σₓ², y∗)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a756c-021b-4866-8a7b-89ec119a60e2",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Write a function that takes in an interval $[a,b]$ and a set of data $D$ and creates two plots:\n",
    "1. A plot of $\\mu(x;D)$ together with a plot of $\\mu(x;D)+2*\\sigma(x;D)$ and $\\mu(x;D)-2*\\sigma(x;D))$ on the interval $[a,b]$.\n",
    "2. A plot of $\\mathrm{EI}(x;D)$.\n",
    "\n",
    "In addition, the function should return the value $x$ in the interval with maximum $\\mathrm{EI}(x;D)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a112346-c439-48ff-bf81-09bca4dbf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "\n",
    "function BO_step(a, b, D)\n",
    "    # code here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22686512-0aa1-49df-b4b5-24d8566f0be3",
   "metadata": {},
   "source": [
    "### Optimization loop\n",
    "Finally, let's use our code to find a maximum. In particular, we will try to find the maximum of $\\sin(x)$ on the interval $[0,2\\pi]$. Suppose we start with the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21dd0df-2af7-4b8c-bffa-ff4629f2f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [(0,sin(0)), (3,sin(3)), (6,sin(6))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7e3c4-7dc9-4e09-acc4-52f8025a7122",
   "metadata": {},
   "source": [
    "Let's see what Bayesian optimization is telling us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c22d9-e12a-4e70-af16-bfb29df70553",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = BO_step(0, 2*pi, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378b199-92e6-4faf-92ba-d0f185c6035c",
   "metadata": {},
   "source": [
    "Now we are going to evaluate our function at the $x$ that maximizes the expected improvement and add it to our data. Then we run another step of Bayesian optimization with this new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beff221-8e45-48ac-b136-943224ba956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(D, [x_new, f(x_new)])\n",
    "x_new = BO_step(0, 2*pi, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333de4a-62fc-486b-be6c-bb82ee5fa5e3",
   "metadata": {},
   "source": [
    "What do you notice? Try running the last step a few more times (you can just re-run the same cell). How many steps does it take to get pretty close to the maximum? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83852e3-d064-454e-9a35-97f9468307cb",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "1. Mess with the values of $\\alpha$ and $L$ in the Gaussian kernel. Or mess with your choice of $\\mu_0$ (for example, one could try $\\mu_0(x) = \\frac{1}{3}x$ if one has reason to think that increasing $x$ will, on average, increase the function value. Or maybe try $\\mu_0(x) = -2$.).\n",
    "2. Re-work your code so that it works with vector-valued input (i.e. so that you could optimize a function over a plan, or 3-d space, or ...).\n",
    "3. Write a function that automates the optimization loop. It should keep going until the change in EI over 3 steps is less than a user-specified tolerance. It should return the input $x$ (and the value of $f(x)$) that maximizes $f$ among all the inputs that have been tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7ec3e-ee0e-4dee-bf36-f4df2e7794b5",
   "metadata": {},
   "source": [
    "## General question areas\n",
    "Here is a list of general types of questions that could be on the exam. Some of these are included in this practice workbook and some aren't.\n",
    "- Using Julia's optimization package\n",
    "- Using Julia's ODE package\n",
    "- Implementing a Monte Carlo estimate\n",
    "- Assessing runtimes and space usage\n",
    "- Creating custom data types/structs and defining functions on those structs\n",
    "- 1-liners/array comprehension\n",
    "- Linear algebra, especially linear regression and solving linear systems\n",
    "- Processing strings\n",
    "- Writing recursive functions\n",
    "- Using higher-precision data types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
